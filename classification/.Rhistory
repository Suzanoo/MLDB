pull()
y_test <- test_data %>%
select(matches(y_test)) %>%
pull()
levels <- unique(y_test)
y_pred <- rep(levels[1], length(y_probs))
y_pred[y_probs > 0.5] = levels[2]
cfm <- caret::confusionMatrix(y_pred, y_test)
ggplotConfusionMatrix(cfm)
ggplotConfusionMatrix <- function(m){
mytitle <- paste("Accuracy", scales::percent_format()(m$overall[1]),
', ',
"Kappa", scales::percent_format()(m$overall[2]))
p <-
ggplot(data = as.data.frame(m$table) ,
aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = log(Freq)), colour = "white") +
scale_fill_gradient(low = "white", high = "steelblue") +
geom_text(aes(x = Reference, y = Prediction, label = Freq)) +
theme(legend.position = "none") +
ggtitle(mytitle)
return(p)
}
ggplotConfusionMatrix(cfm)
shiny::runApp()
?glm
runApp()
runApp()
runApp()
runApp()
runApp()
s <- 'y ~ X1 + X2'
s %>%
str_split(pattern = ' ~ ')
s[1]
s[[1]]
x <- s %>%
str_split(pattern = ' ~ ')
x[1]
x[[1]]
length(x)
x <- s %>%
str_split_fixed(pattern = ' ~ ', n = 2)
x
x[1,1]
Smarket
s <- 'Direction'
data %>%
select(matches(s))
data %>%
select(matches(s)) %>%
as.numeric()
attach(Smarket)
ggplotConfusionMatrix <- function(m){
mytitle <- paste("Accuracy", scales::percent_format()(m$overall[1]),
', ',
"Kappa", scales::percent_format()(m$overall[2]))
p <-
ggplot(data = as.data.frame(m$table) ,
aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = log(Freq)), colour = "white") +
scale_fill_gradient(low = "white", high = "steelblue") +
geom_text(aes(x = Reference, y = Prediction, label = Freq)) +
theme(legend.position = "none") +
ggtitle(mytitle)
return(p)
}
data <- Smarket %>%
as_tibble()%>%
mutate(id = row_number())
i <- data %>%
rsample::initial_split(prop = 0.7)
train_data <- rsample::training(i)
test_data <- rsample::testing(i)
s <- 'Direction ~ Lag1+ Lag2'
model <- glm(as.formula(paste0(s)),
data = Smarket,
family = binomial,
subset = train_data$id)
summary(model)
model <- glm(as.formula(s),
data = Smarket,
family = binomial,
subset = train_data$id)
runApp()
runApp()
View(data)
runApp()
runApp()
ui <- dashboardPage(
dashboardHeader(title = 'Classification'),
dashboardSidebar(width = '275',
sidebarMenu(
menuItem('Instruction', tabName = 'instruction', icon = icon('hammer', lib = 'font-awesome')),
menuItem('Table & Correlation', tabName = 'table', icon = icon('table', lib = 'font-awesome')),
menuItem('DS', tabName = 'ds', icon = icon('desktop', lib = 'font-awesome')),
fileInput(inputId = 'f_input', label = 'Upload File'),
div(class='col-lg-12 col-md-12',
hr()),
# Correlation
uiOutput(outputId = 'corre'),
actionButton(inputId = 'button1', label = 'Correlation'),
div(class='col-lg-12 col-md-12',
hr()),
# Train-Test
sliderInput("data_split", label = "Percent Train", min = 0,
max = 100, value = 70, step = 5),
# Fit Model
textInput(inputId = 'formula',
label = 'Creat formula',
placeholder = 'y ~ X1 + X2 + ...'),
actionButton(inputId = 'button2', label = 'Run Model'),
div(class='col-lg-12 col-md-12',
hr())
)
),
dashboardBody(
tabItems(
tabItem(tabName = 'instruction'),
tabItem(tabName = 'table',
fluidRow(
DT::dataTableOutput('view_table')
),
fluidRow(
plotOutput('corr_plot')
)),
tabItem(tabName = 'ds',
fluidRow(
box(verbatimTextOutput('summary')),
box(plotOutput('conf.matrix'))
)
)
)
)
)
###------------------------------------------------------
server <- function(input, output, session){
### RAW MATERIALS
#upload csv file
data <- reactive({
file <- input$f_input
data <- if(!is.null(file)){
read.csv(file$datapath)
} %>%
as_tibble()%>%
mutate(id = row_number())
})
#render RAW table
output$view_table <- DT::renderDataTable(
data(),
options = (list(scrollX = TRUE))
)
###-----------------------------------------
### TRAIN-TEST DATA SPLIT
set.seed(112)
i <- reactive({
set.seed(112)
data() %>%
rsample::initial_split(prop = as.numeric(input$data_split)/100)
})
###-----------------------------------------
### FIT MODEL
model <- eventReactive(input$button2, {
train_data <- rsample::training(i())
test_data <- rsample::testing(i())
##Logistic Regression
glm(as.formula(input$formula),
data = data(),
family = binomial,
subset = train_data$id) #parse index of train
})
output$summary <- renderPrint({
if(!is.null(model())){
summary(model())
}
})
}
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(tidyverse)
library(shiny)
library(shinydashboard)
library(ISLR2)
library(GGally)
library(scales)
?predict
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
data <- Smarket %>%
as_tibble()%>%
mutate(id = row_number())
i <- data %>%
rsample::initial_split(prop = 0.7)
train_data <- rsample::training(i)
test_data <- rsample::testing(i)
s <- 'Direction ~ Lag1+ Lag2'
model <- glm(as.formula(paste0(input$formula)),
data = Smarket,
family = binomial,
subset = train_data$id)
y_probs <- predict(model, test_data, type = "response")
# retrieve response(y) from formula
y_test <- 'Direction'
# pull response(y_test) from test data
y_test <- test_data %>%
select(matches(y_test)) %>%
pull()
# create labels(+, -)
levels <- unique(y_test)
y_pred <- rep(levels[1], length(y_probs))
y_pred[y_probs > 0.5] = levels[2]
y_probs <- predict(model, test_data, type = "response")
model <- glm(as.formula(paste0(input$formula)),
data = Smarket,
family = binomial,
subset = train_data$id)
model <- glm(as.formula(paste0(s)),
data = Smarket,
family = binomial,
subset = train_data$id)
y_probs <- predict(model, test_data, type = "response")
y_test <- 'Direction'
y_test <- test_data %>%
select(matches(y_test)) %>%
pull()
levels <- unique(y_test)
y_pred <- rep(levels[1], length(y_probs))
y_pred[y_probs > 0.5] = levels[2]
y_test <- test_data %>%
select(matches(y_test)) %>%
pull()
y_test <- 'Direction'
y_test <- test_data %>%
select(matches(y_test)) %>%
pull()
levels <- unique(y_test)
y_pred <- rep(levels[1], length(y_probs))
y_pred[y_probs > 0.5] = levels[2]
df1 <- Smarket.2005 %>%
mutate(Class = y_pre
df1 <- Smarket.2005 %>%
mutate(Class = y_pred)
label <- y_pred %>% unlist()
df1 <- Smarket.2005 %>%
mutate(Class = y_pred)
label <- y_pred %>% unlist()
df1 <- test_data %>%
mutate(Class = y_pred)
df1 <- test_data %>%
mutate(Class = y_pred)
ggplot(data = df1,
aes(x=Lag1, y=Lag2))+
geom_point(aes(color = Class,
shape = Class,
alpha = .5))+
ggtitle("GLM fit")+
theme(legend.position = "none")
y_test <- 'Direction'
# pull response(y_test) from test data
y_test <- test_data %>%
select(matches(y_test)) %>%
pull()
# create labels(+, -)
levels <- unique(y_test)
y_pred <- rep(levels[1], length(y_probs))
y_pred[y_probs > 0.5] = levels[2]
df1 <- test_data %>%
mutate(Class = y_pred)
ggplot(data = df1,
aes(x=Lag1, y=Lag2))+
geom_point(aes(color = Class,
shape = Class,
alpha = .5))+
ggtitle("GLM fit")+
theme(legend.position = "none")
runApp()
runApp()
x <- c(0, 1)
c(0, 1) %>% as.factor()
x <- c(0, 1) %>% as.factor()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
attach(Smarket)
train <- (Year <  2005) #index
Smarket.2005 <- Smarket[!train, ] #X_test
Direction.2005 <- Direction[!train] #y_test
df <- data.frame(Smarket.2005[c('Lag1', 'Lag2')], Direction.2005)
names(df) <- c('Lag1', 'Lag2', 'Class')
##Logistic Regression
glm.fit <- glm(Direction ~ Lag1+ Lag2,
data = Smarket,
family = binomial,
subset = train)
summary(model)
glm.probs <- predict(glm.fit, Smarket.2005, type = "response") #y_predict
#transform numerical labels to strings labels
glm.pred <- rep("Down", 252)#create labels vector
glm.pred[glm.probs > 0.5] = "Up"#transforms to "Up" if match prob>0.5
#Confusion matrix
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
#
predict(glm.fit,
newdata = data.frame(
Lag1=c(1.2, 1.5), Lag2=c(1.1, -0.8), type="response"
))
#
df1 <- mutate(Smarket.2005,  "Class"=glm.pred)
p1 <- ggplot(data = df1,
aes(x=Lag1, y=Lag2))+
geom_point(aes(color = Class,
shape = Class,
alpha = .5))+
ggtitle("GLM fit")+
theme(legend.position = "none")
p1
##LDA
# library(MASS)
lda.fit = MASS::lda(Direction ~ Lag1+ Lag2, data = Smarket, subset = train)
lda.fit
lda.fit.pred <- predict(lda.fit, Smarket.2005)
names(lda.fit.pred)
lda.fit.class <- lda.fit.pred$class
table(lda.fit.class, Direction.2005)
mean(lda.fit.class == Direction.2005)
#Apply threshold 50%, 80%
sum(lda.fit.pred$posterior[, 1] >= 0.5)
sum(lda.fit.pred$posterior[, 1] < 0.5)
sum(lda.fit.pred$posterior[, 1] >= 0.8)
lda.fit.pred$posterior[1:20, 1]
lda.fit.pred$class[1:20]
plot(lda.fit.pred$posterior[,1])
predict(lda.fit,
newdata = data.frame(Lag1=c(1.2, 1.5), Lag2=c(1.1, -0.8)),
type="response"
)
df2 <- mutate(Smarket.2005, "Probs"=lda.fit.pred$posterior[, 2], "Class"=lda.fit.pred$class)
p2 <- ggplot(data = df2,
aes(x=Lag1, y=Lag2))+
geom_point(aes(color = Class,
shape = Class,
alpha = .5))+
ggtitle("LDA")+
theme(legend.position = "none")
p2
qda.fit <- MASS::qda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
qda.fit
qda.fit.pred <- predict(qda.fit, Smarket.2005)
qda.class <- qda.fit.pred$class
table(qda.fit.class, Direction.2005)
mean(qda.fit.class == Direction.2005)
predict(qda.fit,
newdata = data.frame(Lag1=c(1.2, 1.5), Lag2=c(1.1, -0.8)),
type="response"
)
df3 <- mutate(Smarket.2005, "Probs"=qda.fit.pred$posterior[, 2], "Class"=qda.fit.pred$class)
p3 <- ggplot(data = df3,
aes(x=Lag1, y=Lag2))+
geom_point(aes(color = Class,
shape = Class,
alpha = .5))+
ggtitle("QDA")+
theme(legend.position = "none")
p3
library(patchwork)
p1|p2|p3
##Naive Bayes
# library(e1071)
nb.fit <- e1071::naiveBayes(Direction ~ Lag1+ Lag2, data = Smarket, subset = train)
nb.fit
nb.fit.pred <- predict(nb.fit, Smarket.2005)
table(nb.fit.pred, Direction.2005)
mean(nb.fit.pred == Direction.2005)
nb.fit.pred2 <- predict(nb.fit, Smarket.2005, type = "raw")
nb.fit.pred2[1:5, ]
predict(nb.fit,
newdata = data.frame(Lag1=c(1.2, 1.5), Lag2=c(1.1, -0.8)),
type = "raw")
df4 = mutate(Smarket.2005, "Class"=nb.fit.pred )
#New data
set.seed((112))
xx1 <- runif(1000, -5, 5)
xx2 <- runif(1000, -5, 5)
yy <- predict(nb.fit,
newdata = data.frame(Lag1=xx1, Lag2=xx2),
type = "raw")
lb <- rep("Down", 1000)#create labels vector placeholder
lb[yy[, 2] > 0.5] = "Up"#transforms to "Up" if match prob>0.5
df5 <- data.frame(xx1, xx2, lb)
names(df5) <- c('Lag1', 'Lag2', 'Class')
p4 <- ggplot()+
#train data
geom_point(data = df,
aes(x = Lag1, y = Lag2,
shape = 'circle',
color = Class))+
#test data
# geom_point(data = df4,
#            aes(x = Lag1, y = Lag2,
#                shape = 'circle',
#                color = Class))+
#new data to see curve
geom_point(data = df5,
aes(x = Lag1, y = Lag2,
shape = 'circle',
color = Class,
alpha = 0.01))+
ggtitle("Naive Bayes")+
theme(legend.position = "none")
p4
(p1|p2)/(p3|p4) +
plot_annotation(
title = "Classification fit",
)
##K-Nearest Neighbors
X_train <- cbind(Lag1, Lag2)[train, ]
X_test <- cbind(Lag1, Lag2)[!train, ]
y_train <- Direction[train]
y_test <- Direction[!train]
plotx <- function(x, y, labels, title){
df <- data.frame("Lag1" = x,
"Lag2" = y,
"Class" = labels)
ggplot(data = df,
aes(x=Lag1, y=Lag2))+
geom_point(aes(color = Class,
shape = Class,
size = 6, alpha = .5))+
ggtitle(title)
}
#Random observation to protect nearest neighbors tied effect
set.seed(1)
# library(class)
knn.pred <- class::knn(X_train, X_test, y_train, k=1)
table(knn.pred, y_test)
mean(knn.pred == y_test)
p5 <- plotx(X_test[, 1], X_test[, 2], knn.pred, "KNN: k=1")
knn.pred3 <- class::knn(X_train, X_test, y_train, k=3)
table(knn.pred3, y_test)
mean(knn.pred3 == y_test)
p6 <- plotx(X_test[, 1], X_test[, 2], knn.pred3, "KNN: k=3")
#---------------------------------------------
knn.pred10 <- class::knn(X_train, X_test, y_train, k=10)
table(knn.pred10, y_test)
mean(knn.pred10 == y_test)
p7 <- plotx(X_test[, 1], X_test[, 2], knn.pred10, "KNN: k=10")
p5/p6/p7
set.seed((112))
xx1 <- runif(1000, -5, 5)
xx2 <- runif(1000, -5, 5)
yy <- predict(nb.fit,
newdata = data.frame(Lag1=xx1, Lag2=xx2),
type = "raw")
lb <- rep("Down", 1000)#create labels vector
lb[yy[, 2] > 0.5] = "Up"#transforms to "Up" if match prob>0.5
df <- data.frame(xx1, xx2, lb)
names(df) <- c('Lag1', 'Lag2', 'Class')
p4 <- ggplot(data = df,
aes(x=Lag1, y=Lag2,
color = Class))+
geom_point(aes(shape = Class,
alpha = .5))+
ggtitle("Naive Bayes")+
theme(legend.position = "none")
p4
set.seed((112))
x_dummy1 <- runif(1000, -5, 5)
x_dummy2 <- runif(1000, -5, 5)
new_data <- data_frame(x_dummy1, x_dummy2)
y_dummy <- rep('Up', 1000
set.seed((112))
x_dummy1 <- runif(1000, -5, 5)
x_dummy2 <- runif(1000, -5, 5)
new_data <- tibble()(x_dummy1, x_dummy2)
y_dummy <- rep('Up', 1000)
new_data <- tibble(x_dummy1, x_dummy2)
new_data %>%
bind_cols(y_dummy)
?set_names()
new_data %>%
bind_cols(y_dummy)%>%
set_names(c('x', 'y', 'Class'))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
